import torch
import torch.utils.data as data
from torch import nn
from torch import optim
import torch.nn.functional as F

import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

from PIL import Image
import json
import argparse


# Define command line arguments
ap = argparse.ArgumentParser()
ap.add_argument('data_dir', nargs='*', action="store", default="/home/workspace/aipnd-project/flowers")
ap.add_argument('--gpu', dest="gpu", action="store", default="gpu")
ap.add_argument('--save_dir', dest="save_dir", action="store", default="/home/workspace/paind-project/checkpoint.pth")
ap.add_argument('--learning_rate', dest="learning_rate", action="store", default=0.001)
ap.add_argument('--dropout', dest = "dropout", action = "store", default = 0.5)
ap.add_argument('--epochs', dest="epochs", action="store", type=int, default=3)
ap.add_argument('--input_size', type=int, dest="input_size", action="store", default=25088)
ap.add_argument('--hidden_units', type=list, dest="hidden_units", action="store", default=[4096,1000])
ap.add_argument('--output_size', type=int, dest="output_size", action="store", default=102)
ap.add_argument('--arch', dest="arch", action="store", default="vgg16", type = str)


pa = ap.parse_args()
where = pa.data_dir
path = pa.save_dir
lr = pa.learning_rate
arch = pa.arch
dropout = pa.dropout
input_size = pa.input_size
hidden_layers = pa.hidden_units
output_size = pa.output_size
power = pa.gpu
epochs = pa.epochs


data_dir = where
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
test_dir = data_dir + '/test'

train_transforms = transforms.Compose([transforms.RandomRotation(30),
                                           transforms.RandomResizedCrop(224),
                                           transforms.RandomHorizontalFlip(),
                                           transforms.ToTensor(),
                                           transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])

test_transforms = transforms.Compose([transforms.Resize(256),
                                          transforms.CenterCrop(224),
                                          transforms.ToTensor(),
                                          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])

validation_transforms = transforms.Compose([transforms.Resize(256),
                                                transforms.CenterCrop(224),
                                                transforms.ToTensor(),
                                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])

train_data = datasets.ImageFolder(train_dir, transform=train_transforms)
validation_data = datasets.ImageFolder(valid_dir, transform=validation_transforms)
test_data = datasets.ImageFolder(test_dir ,transform = test_transforms)

trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)    
validloader = torch.utils.data.DataLoader(validation_data, batch_size =32,shuffle = True)
testloader = torch.utils.data.DataLoader(test_data, batch_size = 20, shuffle = True)

def my_model(arch='vgg16', input_size = 25088, hidden_layers = [4096,1000], output_size = 102, dropout = 0.5, lr = 0.001, power='gpu'):
  
    if arch == 'vgg16':
        model = models.vgg16(pretrained=True)
    elif arch == 'densenet121':
        model = models.densenet121(pretrained=True)
    elif arch == 'alexnet':
        model = models.alexnet(pretrained = True)
    
    for param in model.parameters():
        param.requires_grad = False

        from collections import OrderedDict
        classifier = nn.Sequential(OrderedDict([
                              ('fc1', nn.Linear(input_size, hidden_layers[0])),
                              ('relu1', nn.ReLU()),
                              ('fc2', nn.Linear(hidden_layers[0],hidden_layers[1])),
                              ('relu2', nn.ReLU()),
                              ('fc3', nn.Linear(hidden_layers[1],output_size)),
                              ('output', nn.LogSoftmax(dim=1))
                              ]))


        model.classifier = classifier
        criterion = nn.NLLLoss()
        optimizer = optim.Adam(model.classifier.parameters(), lr )

        if torch.cuda.is_available() and power == 'gpu':
            model.cuda()

        return model, criterion, optimizer


model, criterion, optimizer = my_model(arch, input_size , hidden_layers, output_size , dropout , lr , power)

def train_network(print_every = 10, loader = trainloader):
    steps = 0
    running_loss = 0

    for e in range(epochs):
        running_loss = 0
        for ii, (inputs, labels) in enumerate(loader):
            steps += 1
            if torch.cuda.is_available() and power=='gpu':
                inputs, labels = inputs.to('cuda'), labels.to('cuda')

            optimizer.zero_grad()

            # Forward and backward passes
            outputs = model.forward(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            if steps % print_every == 0:
                model.eval()
                validlost = 0
                accuracy=0


                for ii, (inputs2,labels2) in enumerate(validloader):
                    optimizer.zero_grad()
                    if torch.cuda.is_available():
                        inputs2, labels2 = inputs2.to('cuda:0') , labels2.to('cuda:0')
                        model.to('cuda:0')

                    with torch.no_grad():
                        outputs = model.forward(inputs2)
                        validlost = criterion(outputs,labels2)
                        ps = torch.exp(outputs).data
                        equality = (labels2.data == ps.max(1)[1])
                        accuracy += equality.type_as(torch.FloatTensor()).mean()

                validlost = validlost / len(validloader)
                accuracy = accuracy /len(validloader)

                print("Epoch: {}/{}... ".format(e+1, epochs),
                      "Loss: {:.4f}".format(running_loss/print_every),
                      "Validation Lost {:.4f}".format(validlost),
                      "Accuracy: {:.4f}".format(accuracy))


                running_loss = 0


    print("----------Epochs: {}------------------------------------".format(epochs))
    print("----------Steps: {}-----------------------------".format(steps))

def save_checkpoint(path='checkpoint.pth', arch ='vgg16',input_size=25088 , hidden_layers=[4096,1000], output_size =102 , dropout=0.5, lr=0.001, epochs=3):
    
    model.class_to_idx = train_data.class_to_idx
    model.cpu
    torch.save({'input_size' : 25088,
                'arch' : vgg16,
                'hidden_layers': [4096,1000],
                'output_size': 102,
                'dropout': 0.5,
                'lr' : 0.001,
                'state_dict': model.state_dict(),
                'class_to_idx': model.class_to_idx},
                path)


def load_checkpoint(path='checkpoint.pth'):
    
    checkpoint = torch.load(path)
    arch = checkpoint['arch']
    input_size = checkpoint['input_size']
    hidden_layers = checkpoint['hidden_layers']
    output_size = checkpoint['output_size']
    dropout = checkpoint['dropout']
    lr = checkpoint['lr']
    model,_,_ = my_model(arch,input_size,hidden_layers,output_size,dropout,lr)
    model.class_to_idx = checkpoint['class_to_idx']
    model.load_state_dict(checkpoint['state_dict'])


def process_image(image_path):

    for i in image_path:
        path = str(i)
    img = Image.open(i) 

    make_img_good = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    tensor_image = make_img_good(img)

    return tensor_image


def predict(image_path, topk=5):
    
    if torch.cuda.is_available() and power=='gpu':
        model.to('cuda:0')

    img_torch = process_image(image_path)
    img_torch = img_torch.unsqueeze_(0)
    img_torch = img_torch.float()

    if power == 'gpu':
        with torch.no_grad():
            output = model.forward(img_torch.cuda())
    else:
        with torch.no_grad():
            output=model.forward(img_torch)

    probability = F.softmax(output.data,dim=1)

    return probability.topk(topk)
                                  
train_network(10, trainloader)

save_checkpoint(path, input_size , hidden_layers , output_size, dropout, lr)